{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MP2 Term Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pressure</th>\n",
       "      <th>AFR</th>\n",
       "      <th>Orifice</th>\n",
       "      <th>Focsuing tube dia</th>\n",
       "      <th>STD</th>\n",
       "      <th>MRR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3400</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3</td>\n",
       "      <td>897.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3600</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3600</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2</td>\n",
       "      <td>961.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3600</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3</td>\n",
       "      <td>918.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3800</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2</td>\n",
       "      <td>1043.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pressure   AFR  Orifice  Focsuing tube dia  STD      MRR\n",
       "0      3400  0.55     0.33               0.99    3   897.80\n",
       "1      3600  0.55     0.33               0.99    1  1000.03\n",
       "2      3600  0.55     0.30               1.05    2   961.93\n",
       "3      3600  0.55     0.33               0.90    3   918.21\n",
       "4      3800  0.55     0.33               0.90    2  1043.96"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_excel()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df2.drop(columns=['MRR'])\n",
    "y=df2['MRR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pressure</th>\n",
       "      <th>AFR</th>\n",
       "      <th>Orifice</th>\n",
       "      <th>Focsuing tube dia</th>\n",
       "      <th>STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3400</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3600</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3600</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3600</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3800</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pressure   AFR  Orifice  Focsuing tube dia  STD\n",
       "0      3400  0.55     0.33               0.99    3\n",
       "1      3600  0.55     0.33               0.99    1\n",
       "2      3600  0.55     0.30               1.05    2\n",
       "3      3600  0.55     0.33               0.90    3\n",
       "4      3800  0.55     0.33               0.90    2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28.814218188668423, 2.498081915815343)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y, train_size = 0.7, test_size = 0.3)\n",
    "\n",
    "reg=LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "y_pred_linear = reg.predict(X_test)\n",
    "mape = np.mean((np.array(abs(y_test - y_pred_linear))/np.array(y_test)))*100\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test,y_pred_linear))\n",
    "rmse,mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([924.91280808])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict([[3600,0.55,0.33,0.9,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x180 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "pp = sns.pairplot(data=df2,y_vars=['MRR'],x_vars=['Pressure','AFR','Orifice','Focsuing tube dia','STD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.262884906239675,\n",
       "  7.6912015519880725,\n",
       "  12.47354019707104,\n",
       "  10.84689558278936,\n",
       "  13.466305701511303,\n",
       "  10.758045454600438],\n",
       " [47.46563301132759,\n",
       "  100.3851334702627,\n",
       "  201.82635537726787,\n",
       "  116.80802759771298,\n",
       "  168.45252248365315,\n",
       "  119.73173433441525])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting Mulivariate Polynomial \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "deg=[2,3,4,5,6,7]\n",
    "rmse_poly=np.zeros(len(deg))\n",
    "mape_poly=np.zeros(len(deg))\n",
    "for i in range(len(deg)):\n",
    "    poly = PolynomialFeatures(degree=deg[i])\n",
    "    poly_variables = poly.fit_transform(X)\n",
    "    poly_var_train, poly_var_test, res_train, res_test = train_test_split(poly_variables,y,test_size=0.3)\n",
    "    regression = linear_model.LinearRegression()\n",
    "    model = regression.fit(poly_var_train, res_train)\n",
    "    y_pred = regression.predict(poly_var_test)\n",
    "    \n",
    "    mape_poly[i] = np.mean((np.array(abs(res_test - y_pred))/np.array(res_test)))*100\n",
    "    rmse_poly[i] = np.sqrt(metrics.mean_squared_error(res_test,y_pred))\n",
    "mape_poly=list(mape_poly)\n",
    "rmse_poly=list(rmse_poly)\n",
    "mape_poly,rmse_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best model\n",
    "poly_best = PolynomialFeatures(degree=deg[mape_poly.index(min(mape_poly))])\n",
    "poly_variables = poly_best.fit_transform(X)\n",
    "poly_var_train, poly_var_test, res_train, res_test = train_test_split(poly_variables,y, test_size = 0.3)\n",
    "regression = linear_model.LinearRegression()\n",
    "model = regression.fit(poly_var_train, res_train)\n",
    "deg[mape_poly.index(min(mape_poly))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([918.21000001])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(poly_best.fit_transform([[3600,0.55,0.33,0.9,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.62320220e-04,  7.20039166e+00,  5.64201282e+03,  2.91227912e+03,\n",
       "       -5.86858142e+03, -5.75970575e+02, -3.68053199e-04, -1.65573627e+00,\n",
       "       -3.11129964e+00, -1.20944934e+00, -4.79610199e-01,  3.59029275e+02,\n",
       "       -5.48767691e+03,  2.35787290e+03, -1.42675197e+01,  6.08978675e+03,\n",
       "       -4.40612819e+03,  5.63448794e+03,  5.04288553e+03,  2.44690311e+02,\n",
       "        4.06800000e+01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "import keras\n",
    "model= keras.Sequential()\n",
    "model.add(keras.layers.Dense(5,activation='relu',input_shape=(5,)))\n",
    "model.add(keras.layers.Dense(6,activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 17 samples, validate on 9 samples\n",
      "Epoch 1/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4559713.5000 - accuracy: 0.0000e+00 - val_loss: 4409118.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 120us/step - loss: 4504501.5000 - accuracy: 0.0000e+00 - val_loss: 4354905.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 4449861.0000 - accuracy: 0.0000e+00 - val_loss: 4301269.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 4395796.0000 - accuracy: 0.0000e+00 - val_loss: 4248214.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 236us/step - loss: 4342313.5000 - accuracy: 0.0000e+00 - val_loss: 4195745.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 233us/step - loss: 4289417.5000 - accuracy: 0.0000e+00 - val_loss: 4143865.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 4237109.5000 - accuracy: 0.0000e+00 - val_loss: 4092579.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 4185395.2500 - accuracy: 0.0000e+00 - val_loss: 4041888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 4134278.0000 - accuracy: 0.0000e+00 - val_loss: 3991794.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 4083758.5000 - accuracy: 0.0000e+00 - val_loss: 3942302.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 4033841.0000 - accuracy: 0.0000e+00 - val_loss: 3893410.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 234us/step - loss: 3984524.2500 - accuracy: 0.0000e+00 - val_loss: 3845121.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 296us/step - loss: 3935810.5000 - accuracy: 0.0000e+00 - val_loss: 3797436.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 411us/step - loss: 3887702.0000 - accuracy: 0.0000e+00 - val_loss: 3750353.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 3840196.7500 - accuracy: 0.0000e+00 - val_loss: 3703872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 3793294.2500 - accuracy: 0.0000e+00 - val_loss: 3657992.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 352us/step - loss: 3746995.0000 - accuracy: 0.0000e+00 - val_loss: 3612713.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 3701296.5000 - accuracy: 0.0000e+00 - val_loss: 3568032.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 296us/step - loss: 3656198.0000 - accuracy: 0.0000e+00 - val_loss: 3523946.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 295us/step - loss: 3611695.5000 - accuracy: 0.0000e+00 - val_loss: 3480452.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3567787.7500 - accuracy: 0.0000e+00 - val_loss: 3437550.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3524472.0000 - accuracy: 0.0000e+00 - val_loss: 3395234.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3481744.5000 - accuracy: 0.0000e+00 - val_loss: 3353500.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 3439600.2500 - accuracy: 0.0000e+00 - val_loss: 3312345.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 233us/step - loss: 3398036.5000 - accuracy: 0.0000e+00 - val_loss: 3271763.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 352us/step - loss: 3357048.7500 - accuracy: 0.0000e+00 - val_loss: 3231752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 350us/step - loss: 3316631.7500 - accuracy: 0.0000e+00 - val_loss: 3192304.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 3276780.7500 - accuracy: 0.0000e+00 - val_loss: 3153415.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 3237490.2500 - accuracy: 0.0000e+00 - val_loss: 3115080.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3198755.7500 - accuracy: 0.0000e+00 - val_loss: 3077292.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 173us/step - loss: 3160570.2500 - accuracy: 0.0000e+00 - val_loss: 3040045.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 3122928.2500 - accuracy: 0.0000e+00 - val_loss: 3003334.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 291us/step - loss: 3085822.7500 - accuracy: 0.0000e+00 - val_loss: 2967152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 294us/step - loss: 3049249.0000 - accuracy: 0.0000e+00 - val_loss: 2931492.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 233us/step - loss: 3013199.5000 - accuracy: 0.0000e+00 - val_loss: 2896348.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 2977668.2500 - accuracy: 0.0000e+00 - val_loss: 2861714.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 295us/step - loss: 2942648.7500 - accuracy: 0.0000e+00 - val_loss: 2827581.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 294us/step - loss: 2908132.5000 - accuracy: 0.0000e+00 - val_loss: 2793945.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2874115.0000 - accuracy: 0.0000e+00 - val_loss: 2760797.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 233us/step - loss: 2840587.7500 - accuracy: 0.0000e+00 - val_loss: 2728130.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2807544.0000 - accuracy: 0.0000e+00 - val_loss: 2695938.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2774976.5000 - accuracy: 0.0000e+00 - val_loss: 2664214.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2742879.0000 - accuracy: 0.0000e+00 - val_loss: 2632950.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 2711244.5000 - accuracy: 0.0000e+00 - val_loss: 2602140.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2680065.7500 - accuracy: 0.0000e+00 - val_loss: 2571775.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 232us/step - loss: 2649334.7500 - accuracy: 0.0000e+00 - val_loss: 2541851.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2619046.0000 - accuracy: 0.0000e+00 - val_loss: 2512359.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2589191.5000 - accuracy: 0.0000e+00 - val_loss: 2483291.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 236us/step - loss: 2559764.2500 - accuracy: 0.0000e+00 - val_loss: 2454643.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2530757.7500 - accuracy: 0.0000e+00 - val_loss: 2426405.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 2502164.7500 - accuracy: 0.0000e+00 - val_loss: 2398574.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 294us/step - loss: 2473978.5000 - accuracy: 0.0000e+00 - val_loss: 2371139.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2446192.7500 - accuracy: 0.0000e+00 - val_loss: 2344097.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2418800.5000 - accuracy: 0.0000e+00 - val_loss: 2317438.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 295us/step - loss: 2391794.2500 - accuracy: 0.0000e+00 - val_loss: 2291158.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 295us/step - loss: 2365168.7500 - accuracy: 0.0000e+00 - val_loss: 2265249.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 2338916.2500 - accuracy: 0.0000e+00 - val_loss: 2239706.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2313031.7500 - accuracy: 0.0000e+00 - val_loss: 2214522.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2287508.7500 - accuracy: 0.0000e+00 - val_loss: 2189691.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 294us/step - loss: 2262339.7500 - accuracy: 0.0000e+00 - val_loss: 2165205.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2237519.2500 - accuracy: 0.0000e+00 - val_loss: 2141060.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 178us/step - loss: 2213041.2500 - accuracy: 0.0000e+00 - val_loss: 2117250.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 470us/step - loss: 2188899.7500 - accuracy: 0.0000e+00 - val_loss: 2093769.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 2165089.2500 - accuracy: 0.0000e+00 - val_loss: 2070610.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 2141603.0000 - accuracy: 0.0000e+00 - val_loss: 2047769.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 352us/step - loss: 2118436.2500 - accuracy: 0.0000e+00 - val_loss: 2025239.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 411us/step - loss: 2095582.6250 - accuracy: 0.0000e+00 - val_loss: 2003015.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 410us/step - loss: 2073037.3750 - accuracy: 0.0000e+00 - val_loss: 1981093.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 528us/step - loss: 2050794.8750 - accuracy: 0.0000e+00 - val_loss: 1959465.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 291us/step - loss: 2028849.0000 - accuracy: 0.0000e+00 - val_loss: 1938128.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 294us/step - loss: 2007196.2500 - accuracy: 0.0000e+00 - val_loss: 1917076.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 292us/step - loss: 1985829.3750 - accuracy: 0.0000e+00 - val_loss: 1896303.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 233us/step - loss: 1964744.1250 - accuracy: 0.0000e+00 - val_loss: 1875805.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 234us/step - loss: 1943935.7500 - accuracy: 0.0000e+00 - val_loss: 1855578.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 1923399.5000 - accuracy: 0.0000e+00 - val_loss: 1835616.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 234us/step - loss: 1903130.5000 - accuracy: 0.0000e+00 - val_loss: 1815915.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 1883123.5000 - accuracy: 0.0000e+00 - val_loss: 1796469.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 238us/step - loss: 1863374.2500 - accuracy: 0.0000e+00 - val_loss: 1777275.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1843878.1250 - accuracy: 0.0000e+00 - val_loss: 1758329.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1824631.1250 - accuracy: 0.0000e+00 - val_loss: 1739624.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 1805628.2500 - accuracy: 0.0000e+00 - val_loss: 1721159.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 177us/step - loss: 1786865.7500 - accuracy: 0.0000e+00 - val_loss: 1702927.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1768338.8750 - accuracy: 0.0000e+00 - val_loss: 1684926.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 352us/step - loss: 1750043.5000 - accuracy: 0.0000e+00 - val_loss: 1667151.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 1731976.0000 - accuracy: 0.0000e+00 - val_loss: 1649598.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1714132.2500 - accuracy: 0.0000e+00 - val_loss: 1632263.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1696507.8750 - accuracy: 0.0000e+00 - val_loss: 1615142.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1679099.7500 - accuracy: 0.0000e+00 - val_loss: 1598232.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1661903.7500 - accuracy: 0.0000e+00 - val_loss: 1581530.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1644916.3750 - accuracy: 0.0000e+00 - val_loss: 1565030.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1628133.7500 - accuracy: 0.0000e+00 - val_loss: 1548731.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1611552.5000 - accuracy: 0.0000e+00 - val_loss: 1532628.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1595169.0000 - accuracy: 0.0000e+00 - val_loss: 1516717.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1578979.8750 - accuracy: 0.0000e+00 - val_loss: 1500997.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1562982.0000 - accuracy: 0.0000e+00 - val_loss: 1485463.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1547171.8750 - accuracy: 0.0000e+00 - val_loss: 1470113.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 177us/step - loss: 1531546.6250 - accuracy: 0.0000e+00 - val_loss: 1454942.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1516102.3750 - accuracy: 0.0000e+00 - val_loss: 1439948.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1500836.5000 - accuracy: 0.0000e+00 - val_loss: 1425129.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1485746.1250 - accuracy: 0.0000e+00 - val_loss: 1410480.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1470828.3750 - accuracy: 0.0000e+00 - val_loss: 1396000.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1456080.1250 - accuracy: 0.0000e+00 - val_loss: 1381686.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1441498.5000 - accuracy: 0.0000e+00 - val_loss: 1367533.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1427080.2500 - accuracy: 0.0000e+00 - val_loss: 1353541.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1412823.3750 - accuracy: 0.0000e+00 - val_loss: 1339706.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1398724.7500 - accuracy: 0.0000e+00 - val_loss: 1326025.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1384781.8750 - accuracy: 0.0000e+00 - val_loss: 1312497.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1370992.3750 - accuracy: 0.0000e+00 - val_loss: 1299118.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 1357353.0000 - accuracy: 0.0000e+00 - val_loss: 1285885.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1343861.7500 - accuracy: 0.0000e+00 - val_loss: 1272797.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1330515.7500 - accuracy: 0.0000e+00 - val_loss: 1259851.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1317313.5000 - accuracy: 0.0000e+00 - val_loss: 1247046.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1304252.5000 - accuracy: 0.0000e+00 - val_loss: 1234378.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1291330.0000 - accuracy: 0.0000e+00 - val_loss: 1221845.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1278543.3750 - accuracy: 0.0000e+00 - val_loss: 1209445.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1265891.0000 - accuracy: 0.0000e+00 - val_loss: 1197176.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1253371.0000 - accuracy: 0.0000e+00 - val_loss: 1185035.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1240980.1250 - accuracy: 0.0000e+00 - val_loss: 1173022.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1228717.2500 - accuracy: 0.0000e+00 - val_loss: 1161133.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1216580.1250 - accuracy: 0.0000e+00 - val_loss: 1149367.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1204566.3750 - accuracy: 0.0000e+00 - val_loss: 1137722.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1192675.0000 - accuracy: 0.0000e+00 - val_loss: 1126196.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1180902.7500 - accuracy: 0.0000e+00 - val_loss: 1114786.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1169248.7500 - accuracy: 0.0000e+00 - val_loss: 1103492.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1157710.8750 - accuracy: 0.0000e+00 - val_loss: 1092311.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1146286.8750 - accuracy: 0.0000e+00 - val_loss: 1081242.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1134975.2500 - accuracy: 0.0000e+00 - val_loss: 1070282.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1123774.3750 - accuracy: 0.0000e+00 - val_loss: 1059431.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1112682.7500 - accuracy: 0.0000e+00 - val_loss: 1048686.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1101698.3750 - accuracy: 0.0000e+00 - val_loss: 1038046.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1090819.5000 - accuracy: 0.0000e+00 - val_loss: 1027510.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1080045.0000 - accuracy: 0.0000e+00 - val_loss: 1017075.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 1069372.5000 - accuracy: 0.0000e+00 - val_loss: 1006740.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1058801.0000 - accuracy: 0.0000e+00 - val_loss: 996504.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 118us/step - loss: 1048329.1875 - accuracy: 0.0000e+00 - val_loss: 986365.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 1037954.9375 - accuracy: 0.0000e+00 - val_loss: 976321.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 1027677.0625 - accuracy: 0.0000e+00 - val_loss: 966372.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 1017494.5625 - accuracy: 0.0000e+00 - val_loss: 956517.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 294us/step - loss: 1007406.0000 - accuracy: 0.0000e+00 - val_loss: 946753.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 237us/step - loss: 997409.5000 - accuracy: 0.0000e+00 - val_loss: 937078.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 295us/step - loss: 987503.8750 - accuracy: 0.0000e+00 - val_loss: 927493.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 977687.6875 - accuracy: 0.0000e+00 - val_loss: 917996.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 232us/step - loss: 967960.1250 - accuracy: 0.0000e+00 - val_loss: 908585.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 296us/step - loss: 958319.5000 - accuracy: 0.0000e+00 - val_loss: 899260.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 295us/step - loss: 948764.9375 - accuracy: 0.0000e+00 - val_loss: 890018.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 234us/step - loss: 939294.7500 - accuracy: 0.0000e+00 - val_loss: 880859.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 296us/step - loss: 929908.2500 - accuracy: 0.0000e+00 - val_loss: 871782.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 920604.0000 - accuracy: 0.0000e+00 - val_loss: 862786.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 296us/step - loss: 911380.5000 - accuracy: 0.0000e+00 - val_loss: 853869.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 237us/step - loss: 902237.5625 - accuracy: 0.0000e+00 - val_loss: 845031.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 236us/step - loss: 893173.3125 - accuracy: 0.0000e+00 - val_loss: 836269.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 231us/step - loss: 884186.8750 - accuracy: 0.0000e+00 - val_loss: 827584.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 236us/step - loss: 875277.3750 - accuracy: 0.0000e+00 - val_loss: 818975.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 352us/step - loss: 866443.5625 - accuracy: 0.0000e+00 - val_loss: 810439.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 354us/step - loss: 857684.6250 - accuracy: 0.0000e+00 - val_loss: 801978.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 848999.5625 - accuracy: 0.0000e+00 - val_loss: 793588.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 294us/step - loss: 840387.3125 - accuracy: 0.0000e+00 - val_loss: 785270.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 294us/step - loss: 831847.0625 - accuracy: 0.0000e+00 - val_loss: 777022.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 352us/step - loss: 823377.6875 - accuracy: 0.0000e+00 - val_loss: 768845.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 814978.7500 - accuracy: 0.0000e+00 - val_loss: 760736.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 173us/step - loss: 806649.1875 - accuracy: 0.0000e+00 - val_loss: 752695.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 234us/step - loss: 798388.0000 - accuracy: 0.0000e+00 - val_loss: 744722.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 790194.4375 - accuracy: 0.0000e+00 - val_loss: 736814.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 234us/step - loss: 782067.1250 - accuracy: 0.0000e+00 - val_loss: 728972.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 236us/step - loss: 774005.9375 - accuracy: 0.0000e+00 - val_loss: 721195.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 766010.1250 - accuracy: 0.0000e+00 - val_loss: 713482.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 353us/step - loss: 758078.5625 - accuracy: 0.0000e+00 - val_loss: 705832.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 750210.8125 - accuracy: 0.0000e+00 - val_loss: 698245.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 742406.0000 - accuracy: 0.0000e+00 - val_loss: 690720.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 352us/step - loss: 734663.1875 - accuracy: 0.0000e+00 - val_loss: 683256.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 726982.1250 - accuracy: 0.0000e+00 - val_loss: 675852.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 719361.7500 - accuracy: 0.0000e+00 - val_loss: 668508.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 711801.5625 - accuracy: 0.0000e+00 - val_loss: 661224.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 704300.9375 - accuracy: 0.0000e+00 - val_loss: 653998.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 696859.5625 - accuracy: 0.0000e+00 - val_loss: 646830.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 689476.0000 - accuracy: 0.0000e+00 - val_loss: 639719.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 682150.2500 - accuracy: 0.0000e+00 - val_loss: 632666.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 674881.5625 - accuracy: 0.0000e+00 - val_loss: 625668.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 667669.5625 - accuracy: 0.0000e+00 - val_loss: 618726.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 660513.5000 - accuracy: 0.0000e+00 - val_loss: 611839.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 653412.6250 - accuracy: 0.0000e+00 - val_loss: 605007.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 646366.5625 - accuracy: 0.0000e+00 - val_loss: 598229.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 639375.1250 - accuracy: 0.0000e+00 - val_loss: 591505.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 632437.4375 - accuracy: 0.0000e+00 - val_loss: 584833.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 625552.9375 - accuracy: 0.0000e+00 - val_loss: 578214.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 618721.6875 - accuracy: 0.0000e+00 - val_loss: 571648.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 611942.5625 - accuracy: 0.0000e+00 - val_loss: 565133.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 605215.4375 - accuracy: 0.0000e+00 - val_loss: 558669.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 178us/step - loss: 598539.7500 - accuracy: 0.0000e+00 - val_loss: 552257.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 591915.3125 - accuracy: 0.0000e+00 - val_loss: 545894.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 585341.4375 - accuracy: 0.0000e+00 - val_loss: 539582.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 578817.8125 - accuracy: 0.0000e+00 - val_loss: 533319.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 572344.0000 - accuracy: 0.0000e+00 - val_loss: 527106.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 565919.4375 - accuracy: 0.0000e+00 - val_loss: 520927.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 559529.4375 - accuracy: 0.0000e+00 - val_loss: 514797.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 178us/step - loss: 553188.0625 - accuracy: 0.0000e+00 - val_loss: 508715.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 118us/step - loss: 546895.5625 - accuracy: 0.0000e+00 - val_loss: 502681.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 540651.1875 - accuracy: 0.0000e+00 - val_loss: 496695.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 534454.8750 - accuracy: 0.0000e+00 - val_loss: 490757.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 59us/step - loss: 528306.0000 - accuracy: 0.0000e+00 - val_loss: 484865.6562 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 522204.5312 - accuracy: 0.0000e+00 - val_loss: 479021.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 516150.0625 - accuracy: 0.0000e+00 - val_loss: 473222.7812 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 510142.0625 - accuracy: 0.0000e+00 - val_loss: 467470.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 504180.2812 - accuracy: 0.0000e+00 - val_loss: 461764.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 498264.9375 - accuracy: 0.0000e+00 - val_loss: 456104.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 492395.2500 - accuracy: 0.0000e+00 - val_loss: 450489.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 486571.1562 - accuracy: 0.0000e+00 - val_loss: 444919.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 480792.2188 - accuracy: 0.0000e+00 - val_loss: 439393.4688 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 118us/step - loss: 475058.0938 - accuracy: 0.0000e+00 - val_loss: 433913.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 469369.1875 - accuracy: 0.0000e+00 - val_loss: 428476.8438 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 463724.5625 - accuracy: 0.0000e+00 - val_loss: 423084.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 458124.0625 - accuracy: 0.0000e+00 - val_loss: 417736.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 452567.6562 - accuracy: 0.0000e+00 - val_loss: 412431.5938 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 447055.3125 - accuracy: 0.0000e+00 - val_loss: 407170.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 441586.3750 - accuracy: 0.0000e+00 - val_loss: 401952.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 436160.8750 - accuracy: 0.0000e+00 - val_loss: 396777.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 430778.7188 - accuracy: 0.0000e+00 - val_loss: 391645.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 425439.3125 - accuracy: 0.0000e+00 - val_loss: 386555.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 420142.9688 - accuracy: 0.0000e+00 - val_loss: 381508.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 414889.0312 - accuracy: 0.0000e+00 - val_loss: 376503.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 409677.4688 - accuracy: 0.0000e+00 - val_loss: 371541.4688 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 404508.4062 - accuracy: 0.0000e+00 - val_loss: 366620.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 399381.2812 - accuracy: 0.0000e+00 - val_loss: 361741.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 394295.8438 - accuracy: 0.0000e+00 - val_loss: 356903.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 389252.4375 - accuracy: 0.0000e+00 - val_loss: 352107.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 384250.5312 - accuracy: 0.0000e+00 - val_loss: 347353.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 379290.0938 - accuracy: 0.0000e+00 - val_loss: 342639.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 374370.8750 - accuracy: 0.0000e+00 - val_loss: 337966.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 369492.9688 - accuracy: 0.0000e+00 - val_loss: 333334.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 364655.6562 - accuracy: 0.0000e+00 - val_loss: 328743.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 359859.5312 - accuracy: 0.0000e+00 - val_loss: 324192.4688 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 355103.7188 - accuracy: 0.0000e+00 - val_loss: 319682.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 350388.8750 - accuracy: 0.0000e+00 - val_loss: 315211.8438 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 345714.2188 - accuracy: 0.0000e+00 - val_loss: 310781.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 341079.9688 - accuracy: 0.0000e+00 - val_loss: 306391.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 336485.7500 - accuracy: 0.0000e+00 - val_loss: 302041.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 331931.8438 - accuracy: 0.0000e+00 - val_loss: 297730.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 327417.7500 - accuracy: 0.0000e+00 - val_loss: 293460.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 322943.5000 - accuracy: 0.0000e+00 - val_loss: 289228.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 318508.9688 - accuracy: 0.0000e+00 - val_loss: 285036.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 180us/step - loss: 314114.0312 - accuracy: 0.0000e+00 - val_loss: 280883.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 309758.3438 - accuracy: 0.0000e+00 - val_loss: 276769.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 305442.1875 - accuracy: 0.0000e+00 - val_loss: 272695.1875 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 301165.2500 - accuracy: 0.0000e+00 - val_loss: 268659.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 296927.4062 - accuracy: 0.0000e+00 - val_loss: 264662.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 292728.7188 - accuracy: 0.0000e+00 - val_loss: 260704.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 288568.7500 - accuracy: 0.0000e+00 - val_loss: 256784.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 284447.8750 - accuracy: 0.0000e+00 - val_loss: 252910.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 280372.9062 - accuracy: 0.0000e+00 - val_loss: 249066.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 276329.0312 - accuracy: 0.0000e+00 - val_loss: 245262.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 272323.8438 - accuracy: 0.0000e+00 - val_loss: 241495.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 118us/step - loss: 268356.8750 - accuracy: 0.0000e+00 - val_loss: 237766.7812 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 58us/step - loss: 264428.2500 - accuracy: 0.0000e+00 - val_loss: 234075.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 260537.8750 - accuracy: 0.0000e+00 - val_loss: 230423.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 256685.4062 - accuracy: 0.0000e+00 - val_loss: 226807.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 252871.1250 - accuracy: 0.0000e+00 - val_loss: 223229.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 249094.4062 - accuracy: 0.0000e+00 - val_loss: 219689.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 120us/step - loss: 245355.7031 - accuracy: 0.0000e+00 - val_loss: 216186.1875 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 178us/step - loss: 241654.3750 - accuracy: 0.0000e+00 - val_loss: 212720.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 237990.7969 - accuracy: 0.0000e+00 - val_loss: 209291.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 118us/step - loss: 234364.3125 - accuracy: 0.0000e+00 - val_loss: 205899.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 118us/step - loss: 230775.4844 - accuracy: 0.0000e+00 - val_loss: 202544.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 227223.6250 - accuracy: 0.0000e+00 - val_loss: 199226.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 223708.9531 - accuracy: 0.0000e+00 - val_loss: 195944.7812 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 173us/step - loss: 220231.3281 - accuracy: 0.0000e+00 - val_loss: 192699.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 216790.4531 - accuracy: 0.0000e+00 - val_loss: 189490.6562 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 213386.2188 - accuracy: 0.0000e+00 - val_loss: 186318.1875 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 210018.7344 - accuracy: 0.0000e+00 - val_loss: 183181.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 118us/step - loss: 206687.8438 - accuracy: 0.0000e+00 - val_loss: 180081.2656 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 203393.1562 - accuracy: 0.0000e+00 - val_loss: 177016.5469 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 200134.6562 - accuracy: 0.0000e+00 - val_loss: 173987.5938 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 196912.4062 - accuracy: 0.0000e+00 - val_loss: 170994.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 193726.1719 - accuracy: 0.0000e+00 - val_loss: 168036.3594 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 190575.7812 - accuracy: 0.0000e+00 - val_loss: 165113.7969 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 187461.1875 - accuracy: 0.0000e+00 - val_loss: 162226.3594 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 178us/step - loss: 184382.2031 - accuracy: 0.0000e+00 - val_loss: 159373.8594 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 181338.5781 - accuracy: 0.0000e+00 - val_loss: 156556.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 178330.2969 - accuracy: 0.0000e+00 - val_loss: 153773.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 175357.1875 - accuracy: 0.0000e+00 - val_loss: 151025.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 172419.3281 - accuracy: 0.0000e+00 - val_loss: 148311.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 169516.2344 - accuracy: 0.0000e+00 - val_loss: 145631.8594 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 166647.9219 - accuracy: 0.0000e+00 - val_loss: 142986.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 178us/step - loss: 163814.1250 - accuracy: 0.0000e+00 - val_loss: 140374.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 161015.0156 - accuracy: 0.0000e+00 - val_loss: 137797.0156 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 158249.9688 - accuracy: 0.0000e+00 - val_loss: 135252.7812 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 155519.0469 - accuracy: 0.0000e+00 - val_loss: 132742.1406 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 152822.2812 - accuracy: 0.0000e+00 - val_loss: 130264.5547 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 150159.1250 - accuracy: 0.0000e+00 - val_loss: 127820.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 147529.7500 - accuracy: 0.0000e+00 - val_loss: 125408.8438 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 144933.8750 - accuracy: 0.0000e+00 - val_loss: 123030.1562 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 142371.3438 - accuracy: 0.0000e+00 - val_loss: 120684.0859 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 139841.9531 - accuracy: 0.0000e+00 - val_loss: 118373.6797 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 355us/step - loss: 137349.0781 - accuracy: 0.0000e+00 - val_loss: 116092.0859 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 294us/step - loss: 134885.3906 - accuracy: 0.0000e+00 - val_loss: 113842.4688 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 294us/step - loss: 132454.2656 - accuracy: 0.0000e+00 - val_loss: 111624.5938 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 177us/step - loss: 130055.4688 - accuracy: 0.0000e+00 - val_loss: 109438.3828 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 178us/step - loss: 127689.0312 - accuracy: 0.0000e+00 - val_loss: 107283.5391 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 292us/step - loss: 125354.5312 - accuracy: 0.0000e+00 - val_loss: 105160.1016 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 294us/step - loss: 123052.1094 - accuracy: 0.0000e+00 - val_loss: 103067.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 236us/step - loss: 120781.2656 - accuracy: 0.0000e+00 - val_loss: 101005.7031 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 118541.6875 - accuracy: 0.0000e+00 - val_loss: 98974.4922 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 296us/step - loss: 116333.4297 - accuracy: 0.0000e+00 - val_loss: 96973.7109 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 114156.3047 - accuracy: 0.0000e+00 - val_loss: 95003.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 112010.1250 - accuracy: 0.0000e+00 - val_loss: 93062.4766 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 237us/step - loss: 109894.5234 - accuracy: 0.0000e+00 - val_loss: 91151.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 107809.3125 - accuracy: 0.0000e+00 - val_loss: 89270.1406 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 105754.3906 - accuracy: 0.0000e+00 - val_loss: 87418.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 352us/step - loss: 103729.4375 - accuracy: 0.0000e+00 - val_loss: 85594.9453 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 234us/step - loss: 101734.2891 - accuracy: 0.0000e+00 - val_loss: 83800.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 99768.7656 - accuracy: 0.0000e+00 - val_loss: 82035.1328 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 352us/step - loss: 97832.5234 - accuracy: 0.0000e+00 - val_loss: 80298.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 95925.5312 - accuracy: 0.0000e+00 - val_loss: 78588.9609 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 233us/step - loss: 94047.3516 - accuracy: 0.0000e+00 - val_loss: 76907.7656 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 92197.9141 - accuracy: 0.0000e+00 - val_loss: 75254.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 90376.9219 - accuracy: 0.0000e+00 - val_loss: 73628.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 88583.9844 - accuracy: 0.0000e+00 - val_loss: 72029.4297 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 86819.2344 - accuracy: 0.0000e+00 - val_loss: 70457.4609 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 85082.0703 - accuracy: 0.0000e+00 - val_loss: 68912.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 120us/step - loss: 83372.5547 - accuracy: 0.0000e+00 - val_loss: 67393.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 81690.1328 - accuracy: 0.0000e+00 - val_loss: 65900.7812 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 80034.7266 - accuracy: 0.0000e+00 - val_loss: 64434.1406 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 78406.2031 - accuracy: 0.0000e+00 - val_loss: 62993.1406 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 76804.1016 - accuracy: 0.0000e+00 - val_loss: 61577.5820 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 75228.3125 - accuracy: 0.0000e+00 - val_loss: 60187.2773 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 73678.5938 - accuracy: 0.0000e+00 - val_loss: 58821.8203 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 72154.6016 - accuracy: 0.0000e+00 - val_loss: 57481.0898 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 70656.2031 - accuracy: 0.0000e+00 - val_loss: 56164.7578 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 69183.0547 - accuracy: 0.0000e+00 - val_loss: 54872.5742 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 67734.9688 - accuracy: 0.0000e+00 - val_loss: 53604.1758 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 66311.5391 - accuracy: 0.0000e+00 - val_loss: 52359.5469 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 64912.7344 - accuracy: 0.0000e+00 - val_loss: 51138.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 177us/step - loss: 63538.0898 - accuracy: 0.0000e+00 - val_loss: 49939.9258 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 62187.4570 - accuracy: 0.0000e+00 - val_loss: 48764.5703 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 60860.6328 - accuracy: 0.0000e+00 - val_loss: 47611.5898 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 59557.0977 - accuracy: 0.0000e+00 - val_loss: 46481.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 58276.9570 - accuracy: 0.0000e+00 - val_loss: 45372.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 57019.7148 - accuracy: 0.0000e+00 - val_loss: 44285.7656 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 55785.0977 - accuracy: 0.0000e+00 - val_loss: 43220.5781 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 54573.0664 - accuracy: 0.0000e+00 - val_loss: 42176.5781 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 53383.1602 - accuracy: 0.0000e+00 - val_loss: 41153.5273 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 52215.1523 - accuracy: 0.0000e+00 - val_loss: 40151.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 51068.6562 - accuracy: 0.0000e+00 - val_loss: 39169.1992 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 49943.6367 - accuracy: 0.0000e+00 - val_loss: 38207.3633 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 48839.7188 - accuracy: 0.0000e+00 - val_loss: 37265.5469 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 47756.6562 - accuracy: 0.0000e+00 - val_loss: 36343.2422 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 46694.1914 - accuracy: 0.0000e+00 - val_loss: 35440.3164 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 234us/step - loss: 45651.9961 - accuracy: 0.0000e+00 - val_loss: 34556.5312 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 44629.9102 - accuracy: 0.0000e+00 - val_loss: 33691.5430 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 43627.6562 - accuracy: 0.0000e+00 - val_loss: 32845.1523 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 42644.9062 - accuracy: 0.0000e+00 - val_loss: 32016.9512 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 41681.3633 - accuracy: 0.0000e+00 - val_loss: 31206.7910 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 40736.8672 - accuracy: 0.0000e+00 - val_loss: 30414.5137 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 39811.1758 - accuracy: 0.0000e+00 - val_loss: 29639.6387 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 38903.9258 - accuracy: 0.0000e+00 - val_loss: 28882.0410 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 38014.9375 - accuracy: 0.0000e+00 - val_loss: 28141.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 37143.9141 - accuracy: 0.0000e+00 - val_loss: 27417.5547 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 36290.6562 - accuracy: 0.0000e+00 - val_loss: 26710.1016 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 35454.7539 - accuracy: 0.0000e+00 - val_loss: 26018.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 34636.0781 - accuracy: 0.0000e+00 - val_loss: 25343.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 33834.4180 - accuracy: 0.0000e+00 - val_loss: 24683.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 33049.3945 - accuracy: 0.0000e+00 - val_loss: 24039.7793 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 118us/step - loss: 32280.8281 - accuracy: 0.0000e+00 - val_loss: 23410.7969 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 31528.4219 - accuracy: 0.0000e+00 - val_loss: 22796.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 30791.9590 - accuracy: 0.0000e+00 - val_loss: 22197.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 120us/step - loss: 30071.2168 - accuracy: 0.0000e+00 - val_loss: 21612.3691 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 29365.8711 - accuracy: 0.0000e+00 - val_loss: 21041.5840 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 28675.7266 - accuracy: 0.0000e+00 - val_loss: 20484.7715 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 120us/step - loss: 28000.5352 - accuracy: 0.0000e+00 - val_loss: 19941.6934 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 27340.1270 - accuracy: 0.0000e+00 - val_loss: 19412.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 26694.1309 - accuracy: 0.0000e+00 - val_loss: 18895.5684 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 26062.3594 - accuracy: 0.0000e+00 - val_loss: 18392.1172 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 25444.5879 - accuracy: 0.0000e+00 - val_loss: 17901.3848 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 24840.5391 - accuracy: 0.0000e+00 - val_loss: 17423.2461 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 24250.1133 - accuracy: 0.0000e+00 - val_loss: 16957.3301 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 118us/step - loss: 23672.9160 - accuracy: 0.0000e+00 - val_loss: 16503.4512 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 23108.7656 - accuracy: 0.0000e+00 - val_loss: 16061.4131 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 118us/step - loss: 22557.4375 - accuracy: 0.0000e+00 - val_loss: 15630.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 22018.7324 - accuracy: 0.0000e+00 - val_loss: 15211.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 21492.4180 - accuracy: 0.0000e+00 - val_loss: 14804.0293 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 20978.2480 - accuracy: 0.0000e+00 - val_loss: 14407.0605 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 20476.0312 - accuracy: 0.0000e+00 - val_loss: 14020.8320 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 19985.5488 - accuracy: 0.0000e+00 - val_loss: 13645.1680 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 19506.6426 - accuracy: 0.0000e+00 - val_loss: 13279.7539 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 19038.9863 - accuracy: 0.0000e+00 - val_loss: 12924.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 18582.3906 - accuracy: 0.0000e+00 - val_loss: 12579.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 18136.6758 - accuracy: 0.0000e+00 - val_loss: 12243.2227 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 17701.6250 - accuracy: 0.0000e+00 - val_loss: 11917.0195 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 17277.1191 - accuracy: 0.0000e+00 - val_loss: 11600.0254 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 16862.8242 - accuracy: 0.0000e+00 - val_loss: 11292.0977 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 16458.5508 - accuracy: 0.0000e+00 - val_loss: 10993.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 16064.1689 - accuracy: 0.0000e+00 - val_loss: 10702.7783 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 15679.5127 - accuracy: 0.0000e+00 - val_loss: 10420.9463 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 15304.2881 - accuracy: 0.0000e+00 - val_loss: 10147.4551 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 14938.3438 - accuracy: 0.0000e+00 - val_loss: 9882.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 14581.5342 - accuracy: 0.0000e+00 - val_loss: 9624.7695 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 14233.7061 - accuracy: 0.0000e+00 - val_loss: 9375.1309 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 120us/step - loss: 13894.5215 - accuracy: 0.0000e+00 - val_loss: 9133.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 13563.8896 - accuracy: 0.0000e+00 - val_loss: 8898.5205 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 13241.6777 - accuracy: 0.0000e+00 - val_loss: 8671.1865 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 120us/step - loss: 12927.6426 - accuracy: 0.0000e+00 - val_loss: 8450.9316 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 232us/step - loss: 12621.6396 - accuracy: 0.0000e+00 - val_loss: 8237.6357 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 236us/step - loss: 12323.5273 - accuracy: 0.0000e+00 - val_loss: 8031.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 12033.0410 - accuracy: 0.0000e+00 - val_loss: 7831.0410 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 11750.0977 - accuracy: 0.0000e+00 - val_loss: 7637.5371 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 11474.5703 - accuracy: 0.0000e+00 - val_loss: 7450.2871 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 11206.2178 - accuracy: 0.0000e+00 - val_loss: 7269.1401 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 10944.8828 - accuracy: 0.0000e+00 - val_loss: 7093.9980 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 10690.4795 - accuracy: 0.0000e+00 - val_loss: 6924.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 177us/step - loss: 10442.7930 - accuracy: 0.0000e+00 - val_loss: 6761.0840 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 352us/step - loss: 10201.7305 - accuracy: 0.0000e+00 - val_loss: 6602.9761 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 9967.0684 - accuracy: 0.0000e+00 - val_loss: 6450.2910 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 177us/step - loss: 9738.6953 - accuracy: 0.0000e+00 - val_loss: 6302.8926 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 9516.5176 - accuracy: 0.0000e+00 - val_loss: 6160.5801 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 9300.2939 - accuracy: 0.0000e+00 - val_loss: 6023.2891 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 295us/step - loss: 9089.9707 - accuracy: 0.0000e+00 - val_loss: 5890.8472 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 295us/step - loss: 8885.3701 - accuracy: 0.0000e+00 - val_loss: 5763.1528 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 177us/step - loss: 8686.3770 - accuracy: 0.0000e+00 - val_loss: 5640.0654 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 8492.8311 - accuracy: 0.0000e+00 - val_loss: 5521.4380 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 8304.6377 - accuracy: 0.0000e+00 - val_loss: 5407.1997 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 292us/step - loss: 8121.6680 - accuracy: 0.0000e+00 - val_loss: 5297.1934 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 352us/step - loss: 7943.7666 - accuracy: 0.0000e+00 - val_loss: 5191.3457 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 7770.8564 - accuracy: 0.0000e+00 - val_loss: 5089.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 295us/step - loss: 7602.7671 - accuracy: 0.0000e+00 - val_loss: 4991.5376 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 7439.4272 - accuracy: 0.0000e+00 - val_loss: 4897.3921 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 7280.6958 - accuracy: 0.0000e+00 - val_loss: 4806.9531 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 293us/step - loss: 7126.4834 - accuracy: 0.0000e+00 - val_loss: 4720.0571 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 234us/step - loss: 6976.6089 - accuracy: 0.0000e+00 - val_loss: 4636.6626 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 6831.0801 - accuracy: 0.0000e+00 - val_loss: 4556.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 6689.7017 - accuracy: 0.0000e+00 - val_loss: 4479.9082 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 178us/step - loss: 6552.3789 - accuracy: 0.0000e+00 - val_loss: 4406.3618 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 6419.0352 - accuracy: 0.0000e+00 - val_loss: 4335.8804 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 6289.5239 - accuracy: 0.0000e+00 - val_loss: 4268.4160 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 6163.8154 - accuracy: 0.0000e+00 - val_loss: 4203.8496 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 177us/step - loss: 6041.7598 - accuracy: 0.0000e+00 - val_loss: 4142.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 5923.3154 - accuracy: 0.0000e+00 - val_loss: 4083.1104 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 5808.3188 - accuracy: 0.0000e+00 - val_loss: 4026.7678 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 5696.7271 - accuracy: 0.0000e+00 - val_loss: 3972.9648 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 5588.4409 - accuracy: 0.0000e+00 - val_loss: 3921.6663 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 5483.3604 - accuracy: 0.0000e+00 - val_loss: 3872.7651 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 5381.4116 - accuracy: 0.0000e+00 - val_loss: 3826.1963 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 178us/step - loss: 5282.5166 - accuracy: 0.0000e+00 - val_loss: 3781.8950 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 5186.5938 - accuracy: 0.0000e+00 - val_loss: 3739.7678 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 235us/step - loss: 5093.5737 - accuracy: 0.0000e+00 - val_loss: 3699.7527 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 115us/step - loss: 5003.3369 - accuracy: 0.0000e+00 - val_loss: 3661.7935 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 4915.8721 - accuracy: 0.0000e+00 - val_loss: 3625.8196 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 4831.0645 - accuracy: 0.0000e+00 - val_loss: 3591.7251 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 4748.8193 - accuracy: 0.0000e+00 - val_loss: 3559.5005 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 4669.1294 - accuracy: 0.0000e+00 - val_loss: 3529.0574 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 4591.8599 - accuracy: 0.0000e+00 - val_loss: 3500.3196 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 4516.9678 - accuracy: 0.0000e+00 - val_loss: 3473.2576 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 4444.3989 - accuracy: 0.0000e+00 - val_loss: 3447.8105 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 118us/step - loss: 4374.0947 - accuracy: 0.0000e+00 - val_loss: 3423.8887 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 4305.9546 - accuracy: 0.0000e+00 - val_loss: 3401.4729 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 233us/step - loss: 4239.9624 - accuracy: 0.0000e+00 - val_loss: 3380.4973 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 177us/step - loss: 4176.0308 - accuracy: 0.0000e+00 - val_loss: 3360.9109 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 4114.0928 - accuracy: 0.0000e+00 - val_loss: 3342.6599 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 175us/step - loss: 4054.1296 - accuracy: 0.0000e+00 - val_loss: 3325.6978 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 174us/step - loss: 3996.0317 - accuracy: 0.0000e+00 - val_loss: 3309.9724 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3939.7891 - accuracy: 0.0000e+00 - val_loss: 3295.4387 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 3885.3506 - accuracy: 0.0000e+00 - val_loss: 3282.0645 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3832.6384 - accuracy: 0.0000e+00 - val_loss: 3269.7908 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 178us/step - loss: 3781.6072 - accuracy: 0.0000e+00 - val_loss: 3258.5811 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 3732.2200 - accuracy: 0.0000e+00 - val_loss: 3248.3945 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 3684.4263 - accuracy: 0.0000e+00 - val_loss: 3239.1792 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3638.1692 - accuracy: 0.0000e+00 - val_loss: 3230.9092 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 3593.4082 - accuracy: 0.0000e+00 - val_loss: 3223.5439 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3550.0947 - accuracy: 0.0000e+00 - val_loss: 3217.0454 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3508.2085 - accuracy: 0.0000e+00 - val_loss: 3211.3821 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 3467.6833 - accuracy: 0.0000e+00 - val_loss: 3206.5046 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 3428.4707 - accuracy: 0.0000e+00 - val_loss: 3202.3955 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 3390.5618 - accuracy: 0.0000e+00 - val_loss: 3199.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 120us/step - loss: 3353.8936 - accuracy: 0.0000e+00 - val_loss: 3196.3391 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 3318.4468 - accuracy: 0.0000e+00 - val_loss: 3194.3142 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 3284.1423 - accuracy: 0.0000e+00 - val_loss: 3192.9561 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 178us/step - loss: 3251.0029 - accuracy: 0.0000e+00 - val_loss: 3192.1875 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3218.9673 - accuracy: 0.0000e+00 - val_loss: 3191.9949 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3187.9968 - accuracy: 0.0000e+00 - val_loss: 3192.3687 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 176us/step - loss: 3158.0586 - accuracy: 0.0000e+00 - val_loss: 3193.2627 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 119us/step - loss: 3129.1162 - accuracy: 0.0000e+00 - val_loss: 3194.6702 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 117us/step - loss: 3101.1582 - accuracy: 0.0000e+00 - val_loss: 3196.5525 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 116us/step - loss: 3074.1406 - accuracy: 0.0000e+00 - val_loss: 3198.8828 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X,y,epochs=500,validation_split=0.33,callbacks=[keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[905.8831]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=np.array([3600,0.55,0.33,0.9,3])\n",
    "model.predict(test_data.reshape(1,5),batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[956.1766]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=np.array([3800,0.4,0.33,0.9,3])\n",
    "model.predict(test_data.reshape(1,5),batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.callbacks import History \n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
